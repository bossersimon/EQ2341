{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8818cdd7",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd75767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PattRecClasses import DiscreteD, GaussD, HMM, MarkovChain\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b7bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alfaHat = [[1.         0.38470424 0.41887466]\n",
      " [0.         0.61529576 0.58112534]]\n",
      "\n",
      "c = [1.         0.16252347 0.82658096 0.05811253]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc = MarkovChain( np.array( [ 1, 0 ] ), np.array( [ [ 0.9, 0.1, 0 ], [ 0, 0.9, 0.1 ] ] ) ) \n",
    "\n",
    "b1 = GaussD( means=[0], stdevs=[1] )   # Distribution for state = 1\n",
    "b2 = GaussD( means=[3], stdevs=[2] )   # Distribution for state = 2\n",
    "\n",
    "x_obs = [-0.2, 2.6, 1.3]\n",
    "pX = np.array([b1.prob(x_obs), b2.prob(x_obs)])\n",
    "sf = [np.max(p) for p in pX.T]\n",
    "\n",
    "\"\"\" assuming you applied forward directly to the scaled probabilities produced\n",
    "by prob. \"\"\"\n",
    "\n",
    "\"\"\" it is likely that your implementation of the Forward Algorithm is correct, but\n",
    "that you are applying it to the true, unscaled probabilities by accounting\n",
    "for the scaling factors(?) already before running forward\"\"\"\n",
    "\n",
    "[alfaHat, c] = mc.forward(pX/sf) ### Needs scaling?\n",
    "\n",
    "print(f\"alfaHat = {alfaHat}\\n\")\n",
    "print(f\"c = {c}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b117122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.187726979475208\n"
     ]
    }
   ],
   "source": [
    "mc = MarkovChain( np.array( [ 1, 0 ] ), np.array( [ [ 0.9, 0.1, 0 ], [ 0, 0.9, 0.1 ] ] ) ) \n",
    "g1 = GaussD( means=[0], stdevs=[1] )   # Distribution for state = 1\n",
    "g2 = GaussD( means=[3], stdevs=[2] )   # Distribution for state = 2\n",
    "\n",
    "x_obs = (-0.2, 2.6, 1.3)\n",
    "h  = HMM( mc, [g1, g2])\n",
    "\n",
    "c = h.logprob(x_obs)\n",
    "print(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f326eeb",
   "metadata": {},
   "source": [
    "## A.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4905c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.16252347 0.82658096 0.05811253]\n",
      "betaHat: [[0.03350622 0.17804095 0.        ]\n",
      " [0.28196753 1.60236855 2.08182773]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'These numerical results require that all calculations use the scaled state-\\nconditional probability values pX as supplied by the OutputDistr prob-\\nmethod (try help GaussD/prob for more information). If you used the accompanying scale factors(?) from prob to undo the scaling before calling\\nbackward, you may get different results'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = MarkovChain( np.array( [ 1, 0 ] ), np.array( [ [ 0.9, 0.1, 0 ], [ 0, 0.9, 0.1 ] ] ) ) \n",
    "\n",
    "b1 = GaussD( means=[0], stdevs=[1] )   # Distribution for state = 1\n",
    "b2 = GaussD( means=[3], stdevs=[2] )   # Distribution for state = 2\n",
    "\n",
    "x_obs = (-0.2, 2.6, 1.3)\n",
    "pX = np.array([b1.prob(x_obs), b2.prob(x_obs)])\n",
    "sf = [np.max(p) for p in pX.T]\n",
    "    \n",
    "[alfaHat, c] = mc.forward(pX/sf)\n",
    "# print(c)\n",
    "\n",
    "betaHat = mc.backward(pX, c)\n",
    "\n",
    "print(f\"betaHat: {betaHat}\")\n",
    "\n",
    "\n",
    "\"\"\"These numerical results require that all calculations use the scaled state-\n",
    "conditional probability values pX as supplied by the OutputDistr prob-\n",
    "method (try help GaussD/prob for more information). If you used the accompanying scale factors(?) from prob to undo the scaling before calling\n",
    "backward, you may get different results\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
