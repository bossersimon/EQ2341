{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c4f905",
   "metadata": {},
   "source": [
    "## Assigmnent 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e859ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PattRecClasses import DiscreteD, GaussD, HMM, MarkovChain\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4546dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/avk256/activity-recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5868d116",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12fc38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc = []\n",
    "#tau = [] # sample index for first sample in each recording\n",
    "\n",
    "for filename in os.listdir('sensorlogger'):\n",
    "    path = os.path.join('sensorlogger',filename)\n",
    "    with open(path) as file:        \n",
    "        if os.path.isfile(path):\n",
    "            lines = [line.split() for line in file]\n",
    "            # abs of norm of acceleration - gravity\n",
    "            acc.append([ np.abs((np.sqrt(float(line[2])**2 + float(line[3])**2 + float(line[4])**2))-9.82) for line in lines ])\n",
    "            #tau.append(len(acc)+1)\n",
    "        \n",
    "        \n",
    "#t = [(float(line[0])-float(lines[0][0]))/1000 for line in lines]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "954046a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/b2hc0i92l22ir2kavnjn3z5z6mzabbvm-glibc-2.34-210/lib/libc.so.6: version `GLIBC_2.38' not found (required by /nix/store/6j6hl9x71gpq4siar7ns8w2fwx0s7d6q-gvfs-1.52.2/lib/gio/modules/libgvfsdbus.so)\n",
      "Failed to load module: /nix/store/6j6hl9x71gpq4siar7ns8w2fwx0s7d6q-gvfs-1.52.2/lib/gio/modules/libgvfsdbus.so\n",
      "QApplication: invalid style override 'gtk2' passed, ignoring it.\n",
      "\tAvailable styles: bb10dark, bb10bright, cleanlooks, gtk2, cde, motif, plastique, Windows, Fusion\n",
      "qt.glx: qglx_findConfig: Failed to finding matching FBConfig for QSurfaceFormat(version 2.0, options QFlags<QSurfaceFormat::FormatOption>(), depthBufferSize -1, redBufferSize 1, greenBufferSize 1, blueBufferSize 1, alphaBufferSize -1, stencilBufferSize -1, samples -1, swapBehavior QSurfaceFormat::SingleBuffer, swapInterval 1, colorSpace QSurfaceFormat::DefaultColorSpace, profile  QSurfaceFormat::NoProfile)\n",
      "No XVisualInfo for format QSurfaceFormat(version 2.0, options QFlags<QSurfaceFormat::FormatOption>(), depthBufferSize -1, redBufferSize 1, greenBufferSize 1, blueBufferSize 1, alphaBufferSize -1, stencilBufferSize -1, samples -1, swapBehavior QSurfaceFormat::SingleBuffer, swapInterval 1, colorSpace QSurfaceFormat::DefaultColorSpace, profile  QSurfaceFormat::NoProfile)\n",
      "Falling back to using screens root_visual.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233,)\n",
      "(6,)\n",
      "(161,)\n",
      "(176,)\n",
      "(310,)\n",
      "(104,)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.figure(figsize= (15,10))\n",
    "plt.subplot(311)\n",
    "plt.plot(acc[0])\n",
    "\n",
    "\"\"\"Windowing\"\"\"\n",
    "wLen = 100 # window length (samples)\n",
    "overlap = 0 # is higher resolution needed?\n",
    "windows = []\n",
    "\n",
    "step = wLen-overlap\n",
    "\n",
    "X = []\n",
    "for rec in acc:\n",
    "    x = []\n",
    "    wnd = []\n",
    "    for n in range(0,len(rec)-wLen +1,step):\n",
    "        x.append( sum(rec[n:n+wLen])/wLen )\n",
    "        wnd.extend( [sum(rec[n:n+wLen])/wLen] *wLen )\n",
    "\n",
    "    print(np.shape(x))\n",
    "    X.append(x)\n",
    "    windows.append(wnd)\n",
    "\n",
    "    \n",
    "\"\"\"Labels\"\"\"\n",
    "S = []\n",
    "\n",
    "\"\"\"Cluster training data into N separate categories, for estimation of output probabilities\"\"\"\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "\n",
    "for rec in X:\n",
    "    s = []\n",
    "    for a in rec:\n",
    "        if a > 3.5:\n",
    "            s.append(3) #running\n",
    "            data3.append(a)\n",
    "        elif a > 0.6:\n",
    "            s.append(2)  #walking\n",
    "            data2.append(a)\n",
    "        else:\n",
    "            s.append(1)  #standing\n",
    "            data1.append(a)\n",
    "            \n",
    "    S.append(s)\n",
    "        \n",
    "colors = {1: 'red', 2: 'green', 3: 'blue'}\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(windows[0])\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot([t2 for t2 in range(0, len(acc[0]), wLen)][:-1], X[0])\n",
    "for i, val in enumerate(S[0]):\n",
    "    plt.scatter(i*wLen, val, color = colors[val])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3faef0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfig, (ax1,ax2,ax3) = plt.subplots(3)\\n\\nax1.hist(data1, bins = 30)\\nax2.hist(data2, bins = 30)\\nax3.hist(data3, bins = 30)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(3)\n",
    "\n",
    "ax1.hist(data1, bins = 30)\n",
    "ax2.hist(data2, bins = 30)\n",
    "ax3.hist(data3, bins = 30)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41589cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/nix-shell.QMcQW7/ipykernel_7527/2181927254.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  datapoints = np.array([X,S]).T\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tau' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m      8\u001b[0m     Writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile)\n\u001b[0;32m----> 9\u001b[0m     Writer\u001b[38;5;241m.\u001b[39mwriterow(tau)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m datapoints:\n\u001b[1;32m     11\u001b[0m         Writer\u001b[38;5;241m.\u001b[39mwriterow(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tau' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Extracting data to csv\"\"\"\n",
    "\n",
    "datapoints = np.array([X,S]).T\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('features.csv', 'w') as csvfile:\n",
    "    Writer = csv.writer(csvfile)\n",
    "    for data in datapoints:\n",
    "        Writer.writerow(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acb9b4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2149082219447096 0.12722765619672527\n",
      "1.7420355493184476 0.45829907888362154\n",
      "5.9660427944252 0.9862693139955239\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Initialization\"\"\"\n",
    "\n",
    "\"\"\"Infinite ergodic HMM may start in any state. Assumption here is that\n",
    "    each state is equally likely to occur as initial state\"\"\"\n",
    "\n",
    "mc = MarkovChain( np.full( (1,3),1/3 ) , np.array( [ [ 0.9, 0.09, 0.01 ], \n",
    "                                                  [ 0.05, 0.9, 0.05 ], \n",
    "                                                  [ 0.01, 0.09 ,0.9] ] ) )\n",
    "\n",
    "\"\"\"The diagonal elements of the transition matrix can be chosen to indicate \n",
    "    approximately the average state durations. Here I assume that each state duration is equally long\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"Output probability distributions must be initialized differently for each state\"\"\"\n",
    "# Maybe do this with separate data?\n",
    "\n",
    "from scipy.stats import norm\n",
    "        \n",
    "mu1, std1 = norm.fit(data1) #standing\n",
    "mu2, std2 = norm.fit(data2) #walking\n",
    "mu3, std3 = norm.fit(data3) #running\n",
    "\n",
    "\n",
    "# Looks reasonable\n",
    "print(mu1,std1)\n",
    "print(mu2,std2)\n",
    "print(mu3,std3)\n",
    "\n",
    "\n",
    "b1 = GaussD( means=[mu1], stdevs=[std1] )   # Distribution for state = standing\n",
    "b2 = GaussD( means=[mu2], stdevs=[std2] )   # Distribution for state = walking\n",
    "b3 = GaussD( means=[mu3], stdevs=[std3] )   # Distribution for state = running\n",
    "\n",
    "\"\"\"Initial HMM\"\"\"\n",
    "\n",
    "h0  = HMM( mc, [b1, b2, b3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554fe4a",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cac37dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4285534  0.29092337 0.28052323]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Updating initial probability vector\"\"\"\n",
    "\n",
    "epsilon = 10e-10\n",
    "\n",
    "\n",
    "gma = []\n",
    "# for x in training data\n",
    "for x_obs in X:\n",
    "    pX = np.array([b1.prob(x_obs), b2.prob(x_obs), b3.prob(x_obs)])\n",
    "    \n",
    "\n",
    "    # replace zero probabilities with some small probability epsilon\n",
    "    with np.nditer(pX, op_flags =['readwrite']) as it:\n",
    "        for x in it:\n",
    "            x[...] = max(x,epsilon)\n",
    "\n",
    "    \"\"\"normalize\"\"\"\n",
    "    pX = pX / np.sum(pX,axis=0)\n",
    "\n",
    "    #sf = [np.max(p) for p in pX.T]\n",
    "    #pX = pX/sf\n",
    "\n",
    "    [alfaHat, c] = mc.forward(pX)\n",
    "    betaHat = mc.backward(pX, c)\n",
    "\n",
    "    tmp = np.multiply(alfaHat, betaHat)\n",
    "    gma_r = np.multiply(tmp,c) # gamma i,t\n",
    "    gma.append(gma_r)\n",
    "        \n",
    "\"\"\"Update equation\"\"\"\n",
    "q_new = np.zeros((1,3))\n",
    "for r in gma:\n",
    "    q_new = q_new + r[:,0]\n",
    "q_new = q_new/len(gma)\n",
    "\n",
    "print(q_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Updating transition probability matrix\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"The factors ξij,t express the conditional probability, given all observations, \n",
    "   that the hidden state was St = i ∩ St+1 =j\"\"\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
